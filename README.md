

# ğŸ“š PRISMA-MARL: Automated Systematic Literature Review with Multi-Agent Reinforcement Learning

This project is a **proof-of-concept (PoC)** for automating systematic literature reviews based on **PRISMA guidelines**, using a **Multi-Agent Reinforcement Learning (MARL)** system. Each agent operates independently and is trained using **agent-specific reward loops**, evaluated via a dynamic **PRISMA Checker**. All documents are pulled from [arXiv.org](https://arxiv.org).

---

## âœ¨ Features

- ğŸ” Automated arXiv search based on topic and date range
- ğŸ§  Multi-agent system: search, abstract filter, full-text decision
- ğŸ§ª PRISMA-based reward functions for each agent
- ğŸ” Centralized Training with Decentralized Execution (CTDE)
- ğŸ“Š Streamlit web interface + CSV/JSON export
- ğŸ’¾ Model saving/loading with live evaluation

---

## âš™ï¸ Architecture (Reward Loop)

```markdown


                  +--------------------------+
                  |        User Input        |
                  +--------------------------+
                           |
           +---------------+---------------+---------------+
           |               |               |               |
    +------+-----+  +------+-----+  +------+-----+  +------+-----+
    | Search Agent|  | Abstract Agent|  | FullText Agent|  |   ...      |
    +------+-----+  +------+-----+  +------+-----+  +------+-----+
           |               |               |
    +------+-----+  +------+-----+  +------+-----+
    | PRISMA Eval |  | PRISMA Eval |  | PRISMA Eval |
    +------+-----+  +------+-----+  +------+-----+
           |               |               |
     Reward + Replay  Reward + Replay  Reward + Replay
           â†‘               â†‘               â†‘
           +---------------+---------------+
                   (Repeat per epoch)
```



---

## ğŸ“ Project Structure
```markdown

prisma\_marl\_project/
â”œâ”€â”€ agents/                   # Modular DQN agents
â”‚   â”œâ”€â”€ search\_agent.py
â”‚   â”œâ”€â”€ title\_abstract\_filter.py
â”‚   â”œâ”€â”€ full\_text\_agent.py
â”‚   â”œâ”€â”€ prisma\_checker.py
â”‚   â””â”€â”€ shared\_enhanced\_dqn.py
â”‚
â”œâ”€â”€ rewards/                 # Custom PRISMA reward logic
â”‚   â””â”€â”€ enhanced\_reward\_system.py
â”‚
â”œâ”€â”€ trainer/                 # Training pipeline
â”‚   â””â”€â”€ train\_agents.py
â”‚
â”œâ”€â”€ utils/                   # ArXiv interface, tokenizer, etc.
â”‚   â”œâ”€â”€ arxiv\_interface.py
â”‚   â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ models/                  # Saved PyTorch model weights
â”‚
â”œâ”€â”€ app.py                   # Streamlit UI
â”œâ”€â”€ main.py                  # CLI review pipeline
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ README.md

````

---

## ğŸš€ Getting Started

### âœ… 1. Clone the Repo

```bash
git clone https://github.com/MOsama10/prisma-marl-review.git
cd prisma-marl-review
````

### âœ… 2. Create & Activate Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate      # Windows
# or
source venv/bin/activate   # macOS/Linux
```

### âœ… 3. Install Requirements

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

---

## ğŸ” Training Agents (Reward Loop)

Train the MARL agents with real arXiv data and PRISMA feedback:

```bash
python trainer/train_agents.py
```

ğŸ“¦ Trained models are saved to `models/`.

---

## ğŸ§ª CLI Inference Mode

Run the review pipeline interactively from terminal:

```bash
python main.py
```

âœ” Enter a topic and year range
ğŸ“„ Outputs top 10 papers to `results.csv`
ğŸ“Š Shows PRISMA compliance score

---

## ğŸŒ Streamlit Web Interface

```bash
streamlit run app.py
```

Features:

* Topic input + date range
* Run reviews interactively
* Download CSV/JSON
* Train agents from sidebar
* Visual PRISMA score and relevance ranking

---

## ğŸ“Š PRISMA Compliance Scoring

Each agent receives structured feedback on:

* Search coverage and strategy
* Abstract clarity and inclusion accuracy
* Methodology and results from full-text
* Synthesis and limitation discussion

The global score is calculated from 8 standard PRISMA checkpoints.

---

## ğŸ‘¤ Author

**Mohamed Osama**
GitHub: [@MOsama10](https://github.com/MOsama10)





